{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95392381-96a4-4bde-a6cc-717f4255a7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Temp\\ipykernel_22296\\1879445934.py\", line 6, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py\", line 113, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV, StratifiedKFold\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:113\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Advanced JEE Dropout Analysis\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, roc_auc_score, roc_curve, \n",
    "                           precision_recall_curve, average_precision_score)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "import shap\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b227277-3b72-4985-9de6-267e9b083b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\14ac0036au\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\14ac0036au\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\14ac0036au\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\14ac0036au\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (2.2.5)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\14ac0036au\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Collecting sklearn-compat<1,>=0.1\n",
      "  Using cached sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\14AC0036AU\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4483e1f-751c-4fb4-afe4-1ef73a4d1dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set style for plots\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Set style for plots\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "## 1. Advanced Data Loading and Initial Exploration\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('JEE_Dropout_After_Class_12.csv')\n",
    "\n",
    "# Advanced data profiling function\n",
    "def advanced_data_profile(df):\n",
    "    profile = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'missing_values': df.isnull().sum(),\n",
    "        'missing_%': (df.isnull().mean() * 100).round(2),\n",
    "        'unique_values': df.nunique(),\n",
    "        'cardinality': df.nunique() / len(df),\n",
    "        'skewness': df.skew(numeric_only=True),\n",
    "        'kurtosis': df.kurt(numeric_only=True)\n",
    "    })\n",
    "    return profile\n",
    "\n",
    "print(\"Advanced Data Profile:\")\n",
    "display(advanced_data_profile(df))\n",
    "\n",
    "# Interactive correlation matrix with Plotly\n",
    "import plotly.express as px\n",
    "\n",
    "corr_matrix = df.select_dtypes(include=['float64', 'int64']).corr()\n",
    "fig = px.imshow(corr_matrix, text_auto=True, aspect=\"auto\", \n",
    "                color_continuous_scale='RdBu_r', title='Interactive Correlation Matrix')\n",
    "fig.show()\n",
    "\n",
    "## 2. Advanced Data Cleaning and Feature Engineering\n",
    "\n",
    "# Advanced outlier detection using IQR and Z-score\n",
    "def detect_outliers(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    \n",
    "    z_scores = (df[col] - df[col].mean()) / df[col].std()\n",
    "    \n",
    "    return {\n",
    "        'IQR_outliers': ((df[col] < lower_bound) | (df[col] > upper_bound)).sum(),\n",
    "        'Z_score_outliers': (abs(z_scores) > 3).sum()\n",
    "    }\n",
    "\n",
    "outlier_report = {}\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    outlier_report[col] = detect_outliers(df, col)\n",
    "\n",
    "print(\"\\nOutlier Report:\")\n",
    "display(pd.DataFrame(outlier_report).T)\n",
    "\n",
    "# Advanced feature engineering\n",
    "df['total_score'] = df['jee_main_score'] * 0.4 + df['jee_advanced_score'] * 0.6\n",
    "df['consistency'] = 1 - (abs(df['jee_main_score'] - df['mock_test_score_avg']) / 100)\n",
    "df['effort_score'] = df['daily_study_hours'] * df['attempt_count']\n",
    "df['parent_edu_score'] = df['parent_education'].map({\n",
    "    'Upto 10th': 1,\n",
    "    '12th': 2,\n",
    "    'Graduate': 3,\n",
    "    'PG': 4\n",
    "})\n",
    "\n",
    "# Create peer pressure score\n",
    "df['peer_pressure_score'] = df['peer_pressure_level'].map({\n",
    "    'Low': 1,\n",
    "    'Medium': 2,\n",
    "    'High': 3\n",
    "})\n",
    "\n",
    "# Create location score (urban = higher)\n",
    "df['location_score'] = df['location_type'].map({\n",
    "    'Rural': 1,\n",
    "    'Semi-Urban': 2,\n",
    "    'Urban': 3\n",
    "})\n",
    "\n",
    "# Create coaching institute tier\n",
    "top_institutes = ['FIITJEE', 'Allen']\n",
    "df['coaching_tier'] = df['coaching_institute'].apply(\n",
    "    lambda x: 1 if x in top_institutes else (2 if x == 'Local' else 3))\n",
    "\n",
    "## 3. Advanced Exploratory Data Analysis (EDA)\n",
    "\n",
    "# Interactive distribution plots with Plotly\n",
    "for col in ['jee_main_score', 'jee_advanced_score', 'mock_test_score_avg', 'class_12_percent']:\n",
    "    fig = px.histogram(df, x=col, color='dropout', marginal=\"box\", \n",
    "                      title=f'Distribution of {col} by Dropout Status',\n",
    "                      barmode='overlay')\n",
    "    fig.show()\n",
    "\n",
    "# Advanced pairplot with target highlighting\n",
    "num_cols = ['jee_main_score', 'jee_advanced_score', 'mock_test_score_avg', \n",
    "           'class_12_percent', 'daily_study_hours', 'total_score']\n",
    "fig = px.scatter_matrix(df, dimensions=num_cols, color='dropout',\n",
    "                       title='Pairplot of Numerical Features by Dropout Status')\n",
    "fig.show()\n",
    "\n",
    "# Interactive sunburst chart for categorical features\n",
    "fig = px.sunburst(df, path=['family_income', 'parent_education', 'dropout'],\n",
    "                 title='Dropout Distribution by Family Income and Parent Education')\n",
    "fig.show()\n",
    "\n",
    "# Advanced time-series like analysis for attempt count\n",
    "attempt_dropout = df.groupby('attempt_count')['dropout'].mean().reset_index()\n",
    "fig = px.line(attempt_dropout, x='attempt_count', y='dropout', \n",
    "             title='Dropout Rate by Attempt Count',\n",
    "             markers=True)\n",
    "fig.update_layout(yaxis_tickformat=\".0%\")\n",
    "fig.show()\n",
    "\n",
    "## 4. Advanced Feature Selection and Preprocessing\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_cols = ['school_board', 'family_income', 'parent_education', \n",
    "                   'location_type', 'peer_pressure_level', 'mental_health_issues',\n",
    "                   'admission_taken', 'coaching_institute', 'coaching_tier']\n",
    "numerical_cols = ['jee_main_score', 'jee_advanced_score', 'mock_test_score_avg',\n",
    "                 'class_12_percent', 'attempt_count', 'daily_study_hours',\n",
    "                 'performance_ratio', 'study_efficiency', 'total_score',\n",
    "                 'consistency', 'effort_score', 'parent_edu_score',\n",
    "                 'peer_pressure_score', 'location_score']\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "## 5. Advanced Modeling with Hyperparameter Tuning\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [None, 10, 20],\n",
    "            'model__min_samples_split': [2, 5],\n",
    "            'model__class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__learning_rate': [0.1, 0.05],\n",
    "            'model__max_depth': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__penalty': ['l1', 'l2'],\n",
    "            'model__solver': ['liblinear'],\n",
    "            'model__class_weight': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Prepare data\n",
    "X = df[numerical_cols + categorical_cols]\n",
    "y = df['dropout']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Model training and evaluation\n",
    "results = {}\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', smote),\n",
    "        ('model', config['model'])\n",
    "    ])\n",
    "    \n",
    "    # Grid search with stratified K-fold\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(pipeline, config['params'], cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': grid.best_estimator_,\n",
    "        'best_params': grid.best_params_,\n",
    "        'best_score': grid.best_score_\n",
    "    }\n",
    "    \n",
    "    # Evaluation\n",
    "    y_pred = grid.predict(X_test)\n",
    "    y_proba = grid.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"Best parameters: {grid.best_params_}\")\n",
    "    print(f\"Best CV AUC: {grid.best_score_:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Select best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['best_score'])\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\nBest model: {best_model_name} with AUC: {results[best_model_name]['best_score']:.4f}\")\n",
    "\n",
    "## 6. Advanced Model Interpretation\n",
    "\n",
    "### 6.1 SHAP Values Analysis\n",
    "# Prepare data for SHAP\n",
    "preprocessed = best_model.named_steps['preprocessor'].transform(X_train)\n",
    "if hasattr(preprocessed, 'toarray'):  # if sparse matrix from one-hot encoding\n",
    "    preprocessed = preprocessed.toarray()\n",
    "\n",
    "# Get feature names\n",
    "numeric_features = numerical_cols\n",
    "categorical_features = best_model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)\n",
    "all_features = np.concatenate([numeric_features, categorical_features])\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model.named_steps['model'])\n",
    "shap_values = explainer.shap_values(preprocessed)\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values[1], preprocessed, feature_names=all_features, plot_type=\"bar\")\n",
    "plt.title('SHAP Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "# Force plot for a specific prediction\n",
    "sample_idx = 0\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][sample_idx, :], \n",
    "               preprocessed[sample_idx, :], feature_names=all_features)\n",
    "\n",
    "### 6.2 Permutation Importance\n",
    "perm = PermutationImportance(best_model.named_steps['model'], random_state=42).fit(preprocessed, y_train)\n",
    "eli5.show_weights(perm, feature_names=all_features)\n",
    "\n",
    "### 6.3 Partial Dependence Plots\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "top_features = [all_features[i] for i in np.argsort(-perm.feature_importances_)[:3]]\n",
    "print(f\"\\nTop 3 most important features: {top_features}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    best_model, X_train, top_features, \n",
    "    feature_names=all_features,\n",
    "    ax=ax)\n",
    "plt.suptitle('Partial Dependence Plots for Top Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## 7. Advanced Model Evaluation\n",
    "\n",
    "### 7.1 ROC and Precision-Recall Curves\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### 7.2 Calibration Plot\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## 8. Deployment-Ready Pipeline\n",
    "\n",
    "# Create final pipeline with best model\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', best_model.named_steps['model'])\n",
    "])\n",
    "\n",
    "# Train on full data\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(final_pipeline, 'jee_dropout_predictor.pkl')\n",
    "\n",
    "# Example prediction\n",
    "sample_data = X.iloc[0:1].copy()\n",
    "print(\"\\nSample prediction:\")\n",
    "print(f\"Input features:\\n{sample_data}\")\n",
    "print(f\"Prediction: {final_pipeline.predict(sample_data)[0]}\")\n",
    "print(f\"Probability: {final_pipeline.predict_proba(sample_data)[0][1]:.2f}\")\n",
    "\n",
    "## 9. Actionable Insights and Recommendations\n",
    "\n",
    "# Get top risk factors\n",
    "shap_values = explainer.shap_values(preprocessed)\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': np.abs(shap_values[1]).mean(axis=0)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_risk_factors = shap_df.head(5)['feature'].tolist()\n",
    "\n",
    "print(\"\\nAdvanced Insights and Recommendations:\")\n",
    "print(\"1. Top 5 Risk Factors for Dropout:\")\n",
    "for i, factor in enumerate(top_risk_factors, 1):\n",
    "    print(f\"   {i}. {factor}\")\n",
    "\n",
    "print(\"\\n2. Intervention Strategies:\")\n",
    "print(\"   - Targeted academic support for students with:\")\n",
    "print(\"     * JEE Main scores below 65\")\n",
    "print(\"     * Mock test averages below 60\")\n",
    "print(\"     * Study hours less than 4 per day\")\n",
    "print(\"   - Mental health counseling programs\")\n",
    "print(\"   - Peer mentoring for students with high peer pressure\")\n",
    "print(\"   - Special coaching for repeat attempt students\")\n",
    "\n",
    "print(\"\\n3. Early Warning System:\")\n",
    "print(\"   - Implement predictive model to flag at-risk students\")\n",
    "print(\"   - Monitor key metrics monthly:\")\n",
    "print(\"     * Performance ratio (JEE Adv/JEE Main)\")\n",
    "print(\"     * Study efficiency (mock scores/study hours)\")\n",
    "print(\"     * Consistency between mock and actual scores\")\n",
    "\n",
    "print(\"\\n4. Parental Engagement:\")\n",
    "print(\"   - Workshops for parents with lower education levels\")\n",
    "print(\"   - Regular progress reports\")\n",
    "print(\"   - Guidance on creating supportive home environments\")\n",
    "\n",
    "print(\"\\n5. Institutional Recommendations:\")\n",
    "print(\"   - Coaching institutes should track these risk factors\")\n",
    "print(\"   - Develop tiered intervention programs\")\n",
    "print(\"   - Focus on building consistency in performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4950b7-e7b0-46a5-a749-da63632019f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
